# Interroger la bdd qdrant
import os
from langchain.docstore.document import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_qdrant import Qdrant
from qdrant_client import QdrantClient

# ğŸ’¬ Pose ta question ici
query = "Quelle est la place du cinÃ©ma Ã  Marseille dans l'Ã©conomie et l'attractivitÃ© du territoire ?"

# ğŸ“ Connexion Ã  Qdrant
qdrant_url = "http://host.docker.internal:6333"
collection_name = "enriched_chunks_collection"

# ğŸ¤— Embeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ğŸ”Œ Client Qdrant
qdrant_client = QdrantClient(url=qdrant_url)

# ğŸ” CrÃ©ation du vector store (lecture seule)
vector_store = Qdrant(
    client=qdrant_client,
    collection_name=collection_name,
    embeddings=embeddings,
)

# ğŸ” Recherche vectorielle
docs = vector_store.similarity_search(query, k=5)

# ğŸ“‹ Affichage des rÃ©sultats
print("\n--- RÃ©sultats de la recherche ---\n")
all_context = ""
for i, doc in enumerate(docs, 1):
    print(f"RÃ©sultat {i} :")
    print(doc.page_content.strip()[:1000], "...")  # Petit extrait
    print("ğŸ“Œ Source :", doc.metadata.get("source"))
    print("ğŸ“– Titre  :", doc.metadata.get("title"))
    print("ğŸ“„ Page   :", doc.metadata.get("start_page"))
    print("-" * 60)
    all_context += doc.page_content + "\n"

# ğŸ§  SynthÃ¨se simple Ã  partir du contexte
print("\n--- SynthÃ¨se de la rÃ©ponse (rÃ©sumÃ© naÃ¯f) ---\n")

if all_context:
    print("Tout est afficher correctment")
else:
    print("Aucun contenu pertinent trouvÃ© dans la base vectorielle.")

